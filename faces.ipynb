{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /Users/teodimov/anaconda3/lib/python3.11/site-packages (0.3.4)\n",
      "Requirement already satisfied: packaging in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from kagglehub) (23.0)\n",
      "Requirement already satisfied: requests in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from kagglehub) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from requests->kagglehub) (2023.7.22)\n",
      "Path to dataset files: /Users/teodimov/.cache/kagglehub/datasets/jangedoo/utkface-new/versions/1\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jangedoo/utkface-new\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files found: 66976\n",
      "Sample files: ['/Users/teodimov/.cache/kagglehub/datasets/jangedoo/utkface-new/versions/1/crop_part1/9_1_2_20161219204347420.jpg.chip.jpg', '/Users/teodimov/.cache/kagglehub/datasets/jangedoo/utkface-new/versions/1/crop_part1/1_1_2_20161219154612988.jpg.chip.jpg', '/Users/teodimov/.cache/kagglehub/datasets/jangedoo/utkface-new/versions/1/crop_part1/16_0_0_20170104003740977.jpg.chip.jpg', '/Users/teodimov/.cache/kagglehub/datasets/jangedoo/utkface-new/versions/1/crop_part1/1_1_3_20161219230734016.jpg.chip.jpg', '/Users/teodimov/.cache/kagglehub/datasets/jangedoo/utkface-new/versions/1/crop_part1/26_1_1_20170103181931657.jpg.chip.jpg']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "image_files = glob(os.path.join(dataset_path, '**/*.*'), recursive=True)\n",
    "print(\"Number of files found:\", len(image_files))\n",
    "print(\"Sample files:\", image_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): \\ DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "| DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/osx-arm64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/osx-arm64/current_repodata.json HTTP/1.1\" 304 0\n",
      "done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.2\n",
      "  latest version: 24.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.11.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/teodimov/anaconda3/envs/vit_env\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.9\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ca-certificates    pkgs/main/osx-arm64::ca-certificates-2024.9.24-hca03da5_0 \n",
      "  libcxx             pkgs/main/osx-arm64::libcxx-14.0.6-h848a8c0_0 \n",
      "  libffi             pkgs/main/osx-arm64::libffi-3.4.4-hca03da5_1 \n",
      "  ncurses            pkgs/main/osx-arm64::ncurses-6.4-h313beb8_0 \n",
      "  openssl            pkgs/main/osx-arm64::openssl-3.0.15-h80987f9_0 \n",
      "  pip                pkgs/main/osx-arm64::pip-24.2-py39hca03da5_0 \n",
      "  python             pkgs/main/osx-arm64::python-3.9.20-hb885b13_1 \n",
      "  readline           pkgs/main/osx-arm64::readline-8.2-h1a28f6b_0 \n",
      "  setuptools         pkgs/main/osx-arm64::setuptools-75.1.0-py39hca03da5_0 \n",
      "  sqlite             pkgs/main/osx-arm64::sqlite-3.45.3-h80987f9_0 \n",
      "  tk                 pkgs/main/osx-arm64::tk-8.6.14-h6ba3021_0 \n",
      "  tzdata             pkgs/main/noarch::tzdata-2024b-h04d1e81_0 \n",
      "  wheel              pkgs/main/osx-arm64::wheel-0.44.0-py39hca03da5_0 \n",
      "  xz                 pkgs/main/osx-arm64::xz-5.4.6-h80987f9_1 \n",
      "  zlib               pkgs/main/osx-arm64::zlib-1.2.13-h18a0788_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate vit_env\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "usage: conda [-h] [--no-plugins] [-V] COMMAND ...\n",
      "conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'build', 'convert', 'debug', 'develop', 'doctor', 'index', 'inspect', 'metapackage', 'render', 'skeleton', 'pack', 'server', 'content-trust', 'repo', 'verify', 'env', 'token')\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /Users/teodimov/anaconda3/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /Users/teodimov/anaconda3/lib/python3.11/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /Users/teodimov/anaconda3/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Users/teodimov/anaconda3/lib/python3.11/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/teodimov/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda create -n vit_env python=3.9 -y\n",
    "%conda activate vit_env\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "class UTKFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = glob(os.path.join(root_dir, '**/*.chip.jpg'), recursive=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = int(os.path.basename(img_name).split('_')[0])  # Extract age\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset: 66976\n",
      "Sample image shape: torch.Size([3, 224, 224])\n",
      "Sample label (age): 9\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/Users/teodimov/.cache/kagglehub/datasets/jangedoo/utkface-new/versions/1\"\n",
    "dataset = UTKFaceDataset(root_dir=dataset_path, transform=transform)\n",
    "\n",
    "print(\"Number of samples in dataset:\", len(dataset))\n",
    "\n",
    "# Check a sample\n",
    "sample_image, sample_label = dataset[0]\n",
    "print(\"Sample image shape:\", sample_image.shape)\n",
    "print(\"Sample label (age):\", sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset_path = \"/Users/teodimov/.cache/kagglehub/datasets/jangedoo/utkface-new/versions/1\"\n",
    "dataset = UTKFaceDataset(root_dir=dataset_path, transform=transform)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teodimov/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b5ed08ef604f6f83ab5c8c1a8e9a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a828b31b55460e915e3188057ba022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load pre-trained Vision Transformer\n",
    "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "# Modify the classification head for regression\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.config.hidden_size, 256),  # Add a hidden layer\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 1)  # Output a single value for regression\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 2/1675 [00:46<10:47:41, 23.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adamw.py:220\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    207\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    209\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    210\u001b[0m         group,\n\u001b[1;32m    211\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         state_steps,\n\u001b[1;32m    218\u001b[0m     )\n\u001b[0;32m--> 220\u001b[0m     adamw(\n\u001b[1;32m    221\u001b[0m         params_with_grad,\n\u001b[1;32m    222\u001b[0m         grads,\n\u001b[1;32m    223\u001b[0m         exp_avgs,\n\u001b[1;32m    224\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    225\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    226\u001b[0m         state_steps,\n\u001b[1;32m    227\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    228\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    229\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    230\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    231\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    232\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    233\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    234\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    235\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    236\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    237\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    238\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    239\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    240\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adamw.py:782\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 782\u001b[0m func(\n\u001b[1;32m    783\u001b[0m     params,\n\u001b[1;32m    784\u001b[0m     grads,\n\u001b[1;32m    785\u001b[0m     exp_avgs,\n\u001b[1;32m    786\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    787\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    788\u001b[0m     state_steps,\n\u001b[1;32m    789\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    790\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    791\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    792\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    793\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    794\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    795\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    796\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    797\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    798\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    799\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[1;32m    800\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    801\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adamw.py:376\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    375\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 376\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    379\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "epochs = 5  # Adjust based on your preference\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {running_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "model.eval()\n",
    "val_labels = []\n",
    "val_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device, dtype=torch.float32)\n",
    "\n",
    "        outputs = model(images).logits.squeeze()\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "        val_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "mae = mean_absolute_error(val_labels, val_predictions)\n",
    "print(f\"Validation Mean Absolute Error (MAE): {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"vit_age_prediction.pth\")\n",
    "print(\"Model saved as vit_age_prediction.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
